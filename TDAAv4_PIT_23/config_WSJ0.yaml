#coding=utf-8
data:  './data/data/save_data'
log:  './data/data/log/'
epoch:  300 #epoch总数
batch_size: 1
param_init:  0.1
optim:  'adam'
loss: 'focal_loss'
use_center_loss: 0
#loss: 'cross_entropy'

warmup: -1 # 设为-1就是原来的方式
learning_rate:  0.00004 #如果不用warmup

#warmup: 1600 #前warmup步开始热生，最后就是warmup**(-0.5)的这么大
#learning_rate:  0.04 # 热生之后是learning_rate*warmup**(-0.5) 这么大

max_grad_norm:  5
learning_rate_decay:  0.5

mask:  1
schedule:  1
bidirec:  1
start_decay_at:  5
emb_size:  256 #decoder部分的说话人的初始化emb
encoder_hidden_size:  256
decoder_hidden_size:  512
num_layers:  4
dropout:  0.5
max_tgt_len:  5
eval_interval:  2000
save_interval:  2000
max_generator_batches:  32
metric:  ['hamming_loss', 'micro_f1']
shared_vocab:  0
WFM: 0
PSM: 1
frame_mask: 0
MLMSE: 0
beam_size:  5
tmp_score: 0
#tmp_score: 50000
top1: 0 #控制是否用top-1的方法来生产第二个通道
ct_recu: 0 #控制是否采用att递减的ct构成

# query选项部分
use_emb: 0 #用transformer的类似spk emb的那个座位query
PIT_training: 1

use_tas: 1
all_soft: 0 # 这个是决定global emb是不是全用soft的

global_emb:  1
#global_hidden: 0
#SPK_EMB_SIZE: 256 #注意这个东西需要和上面的spk_emb（如果是global_emb的话）,否认则就跟decoder的hidden_size对应
global_hidden: 1
SPK_EMB_SIZE : 512 #注意这个东西需要和上面的spk_emb（如果是global_emb的话）,否认则就跟decoder的hidden_size对应

#global_emb:  0
#SPK_EMB_SIZE : 512 #注意这个东西需要和上面的spk_emb（如果是global_emb的话）,否认则就跟decoder的hidden_size对应
#hidden_mix: 0 #这个模式是不采用global emb的时候，把hidden和下一步的embeding一起cat起来作为ss的输入进去。

#hidden_mix: 0 #这个模式是不采用global emb的时候，把hidden和下一步的embeding一起cat起来作为ss的输入进去。
#hidden_mix: 1 #这个模式是不采用global emb的时候，把hidden和下一步的embeding一起cat起来作为ss的输入进去。
#SPK_EMB_SIZE : 768 #512+256 注意这个东西需要和上面的spk_emb（如果是global_emb的话）,否认则就跟decoder的hidden_size对应
schmidt: 0
unit_norm: 1 #hidden use the unit circle, >0.9 will add the loss.
#unit_norm: 0.9 #hidden use the unit circle, >0.9 will add the loss.
reID: 0
is_SelfTune :  0
is_dis: 0
speech_cnn_net: 0 #是否采用CNN的结构来抽取
relitu: 0
# 设定speech multi acc的阈值alpha
ALPHA:  0.5
quchong_alpha: 1


# 设定最小混叠说话人数，Minimum number of mixed speakers for training
MIN_MIX:  2
# 设定最大混叠说话人数，Maximum number of mixed speakers for training
MAX_MIX:  3
# mode: 1 纯净语音刺激, 2 图片刺激, 3 视频刺激, 4 top-down概念刺激
MODE:  1
# 数据集
# 1包括：THCHS-30 或者 WSJ0, TIMIT做为模型调试,或者CN数据集
# 2包括：ＭNIST
# 3包括：AVA,GRID
# 4包括：
# DATASET :  'GRID'
DATASET :  'WSJ0'
#　组件
is_ComlexMask:  1
num_samples_one_epoch: 20000 #每一个epoch里的samples总数，用来控制epoch的大小

# 是否在训练阶段用Ground Truth的分类结果
Ground_truth:  1
#query是否经过memory的再次更新
Comm_with_Memory: 0
# DNN/RNN隐层的维度 hidden units
HIDDEN_UNITS:  300
# DNN/RNN层数
NUM_LAYERS:  3
# Embedding大小,主要是给语音第三维那部分的
EMBEDDING_SIZE:  50

ATT_SIZE: 100 # 这个是SS里面参数ATT的最外层的统一的大小
# 是否丰富数据
AUGMENT_DATA:  0
# set the max epoch of training
MAX_EPOCH:  600
# epoch size
EPOCH_SIZE:  600
# feature frame rate
#FRAME_RATE:  16000
FRAME_RATE:  8000
# 帧时长(ms)
# FRAME_LENGTH :  int(0.032 * FRAME_RATE)
FRAME_LENGTH: 256
# 帧移(ms)
FRAME_SHIFT:  64
# 是否shuffle_batch,由于现在都是随机采样，这个参数没有意义了
SHUFFLE_BATCH:  0
voice_dB: 2.5 # 配置从-db～db的随机音量大小变换
noise_dB: -10 # 从noise——db 到 0 的噪音变换
normalize: 1 #是否波形归一化
# 设置训练/开发/验证模型的最大语音长度(秒)
MIN_LEN:  40000
#MAX_LEN :  FRAME_RATE*MAX_LEN
#MAX_LEN :  160000
MAX_LEN:  48000 # 8s最长的 避免多的无人声区域
MAX_LEN_limit:  80000 # 设置一个非常大的只，就等于没有限制了
# 帧长
WINDOWS:  FRAME_LENGTH
START_EALY_STOP:  0
# 特征Spectral of Log Spectral
IS_LOG_SPECTRAL :  0
# DB_THRESHOLD :  40  # None
# 添加背景噪音（Str）
channel_first: 1
